{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9729904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.12/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./.venv/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.3.5)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.3.3)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl (37.9 MB)\n",
      "Downloading numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, opencv-python\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.3.5\n",
      "\u001b[2K    Uninstalling numpy-2.3.5:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.5\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [opencv-python]0m [opencv-python]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.2.6 opencv-python-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install matplotlib \n",
    "!pip install numpy scikit-learn pandas opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a422a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c3e17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images and do some preprocessing\n",
    "\n",
    "#size for all images\n",
    "image_resize = (128, 128)\n",
    "\n",
    "#load and save the images \n",
    "def process_and_save(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Load an image, convert to grayscale, resize, and save.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(input_path)\n",
    "\n",
    "    #for missing images \n",
    "    if img is None:\n",
    "        print(\"Could not load:\", input_path)\n",
    "        return\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #covert to grayscale\n",
    "    img = cv2.resize(img, image_resize) #resize\n",
    "    cv2.imwrite(output_path, img) #save \n",
    "\n",
    "\n",
    "#save output path to a folder\n",
    "def process_folder(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process every image in an input folder and save to output.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        in_path = os.path.join(input_dir, filename)\n",
    "        out_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        if os.path.isfile(in_path):\n",
    "            process_and_save(in_path, out_path)\n",
    "\n",
    "#folders for eyes to save the datasets\n",
    "eye_out_open = \"Processed_Datasets/eyes/open_eye\"\n",
    "eye_out_closed = \"Processed_Datasets/eyes/closed_eye\"\n",
    "\n",
    "#folders containing raw data for eyes\n",
    "eye_sources_open = [\"Raw_Data/Open_Eyes\"]\n",
    "eye_sources_closed = [\"Raw_Data/Closed_Eyes\"]\n",
    "\n",
    "#process open eys \n",
    "for fldr in eye_sources_open:\n",
    "    process_folder(fldr, eye_out_open)\n",
    "\n",
    "# PROCESS CLOSED EYES\n",
    "for fldr in eye_sources_closed:\n",
    "    process_folder(fldr, eye_out_closed)\n",
    "\n",
    "#folders for mouths to save the datasets\n",
    "mouth_out_yawn = \"Processed_Datasets/mouth/yawn\"\n",
    "mouth_out_noyawn  = \"Processed_Datasets/mouth/no_yawn\"\n",
    "\n",
    "#folders containing raw data for mouths\n",
    "mouth_sources_yawn = [\"Raw_Data/Yawn\"]\n",
    "mouth_sources_noyawn = [\"Raw_Data/No_Yawn\"]\n",
    "\n",
    "\n",
    "# PROCESS YAWN MOUTHS\n",
    "for fldr in mouth_sources_yawn:\n",
    "    process_folder(fldr, mouth_out_yawn)\n",
    "\n",
    "# PROCESS NO-YAWN MOUTHS\n",
    "for fldr in mouth_sources_noyawn:\n",
    "    process_folder(fldr, mouth_out_noyawn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2025ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277417b",
   "metadata": {},
   "source": [
    "**EYE CNN MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d342d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the processed datasets and preparing them for model training\n",
    "\n",
    "def load_eye_dataset():\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # 0 = open, 1 = closed\n",
    "    base_paths = {0: \"Processed_Datasets/eyes/open_eye\",\n",
    "                  1: \"Processed_Datasets/eyes/closed_eye\"}\n",
    "\n",
    "    for label, folder in base_paths.items():\n",
    "        for filename in os.listdir(folder):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if img is None: #handles missing data\n",
    "                continue\n",
    "\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            img = np.expand_dims(img, axis=-1) #Axis is 1 for grayscale\n",
    "\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_eye, y_eye = load_eye_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdee9844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 300ms/step - accuracy: 0.5000 - loss: 0.7083 - val_accuracy: 0.5000 - val_loss: 0.6660\n",
      "Epoch 2/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 347ms/step - accuracy: 0.6375 - loss: 0.5758 - val_accuracy: 0.9438 - val_loss: 0.3828\n",
      "Epoch 3/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 304ms/step - accuracy: 0.9047 - loss: 0.2675 - val_accuracy: 0.9875 - val_loss: 0.1306\n",
      "Epoch 4/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 298ms/step - accuracy: 0.9812 - loss: 0.1030 - val_accuracy: 0.9937 - val_loss: 0.0413\n",
      "Epoch 5/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 303ms/step - accuracy: 0.9891 - loss: 0.0311 - val_accuracy: 1.0000 - val_loss: 0.0061\n",
      "Epoch 6/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.9937 - loss: 0.0239 - val_accuracy: 1.0000 - val_loss: 0.0061\n",
      "Epoch 7/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 440ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 8/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 369ms/step - accuracy: 0.9969 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 9/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.9953 - loss: 0.0119 - val_accuracy: 0.9937 - val_loss: 0.0125\n",
      "Epoch 10/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9937 - val_loss: 0.0055\n",
      "Epoch 11/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 392ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 3.3487e-04\n",
      "Epoch 12/12\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 1.2253e-04\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "X_eye_train, X_eye_test, y_eye_train, y_eye_test = train_test_split(\n",
    "    X_eye, y_eye,\n",
    "    test_size=0.2, #20% test size\n",
    "    stratify=y_eye, #equal class distribution\n",
    "    random_state=42 #for reproducibility\n",
    ")\n",
    "\n",
    "#model architecture for eye state classification\n",
    "def build_eye_cnn():\n",
    "    model = models.Sequential([\n",
    "\n",
    "        # Input shape: 128x128 grayscale\n",
    "        layers.Input(shape=(128, 128, 1)),\n",
    "\n",
    "        # Block 1\n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        # Block 2\n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        # Block 3\n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        # Dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),     # Prevent overfitting\n",
    "        layers.Dense(1, activation='sigmoid') #output layer\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "eye_model = build_eye_cnn()\n",
    "\n",
    "history_eye = eye_model.fit(\n",
    "    X_eye_train, y_eye_train,\n",
    "    validation_data=(X_eye_test, y_eye_test),\n",
    "    epochs=12,\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b35439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
